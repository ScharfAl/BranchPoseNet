{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439436ba-d665-4b91-ac66-c2194789917e",
   "metadata": {},
   "source": [
    "# Whorls pose estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a9a54-0419-48c1-85d4-9042c4f2bf3c",
   "metadata": {},
   "source": [
    "### If required install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c62a6bd8-9eee-463b-9ac0-4a6733664505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ultralytics\n",
    "#!python -m pip install \"laspy[lazrs,laszip]\"\n",
    "#!pip install comet_ml \n",
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cccbe1-3557-4995-a0a9-f20e696ea4c3",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbebbeaf-e3f9-4fab-8d4b-ba4a884a05a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os, glob, shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import laspy\n",
    "from PIL import Image\n",
    "import re\n",
    "from scipy.spatial import cKDTree\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "import ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37272bc9-c733-4151-a0d6-42506a267b3f",
   "metadata": {},
   "source": [
    "### Load custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d22d522-b7c0-4c8a-bd86-938efa00ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom functions\n",
    "def rotate_point_cloud(point_cloud, angle_degrees, center_point):\n",
    "    \"\"\"\n",
    "    Rotate the point cloud around a center point by a given angle in degrees.\n",
    "    \"\"\"\n",
    "    theta = np.radians(angle_degrees)\n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "    R = np.array(((c, -s), (s, c)))\n",
    "    rotated_points = np.dot(point_cloud[:, :2] - center_point, R.T) + center_point\n",
    "    return np.hstack((rotated_points, point_cloud[:, 2].reshape(-1, 1)))\n",
    "\n",
    "def slice_tree_center_thick_slices(point_cloud, slice_thickness=10):\n",
    "    \"\"\"\n",
    "    Take thick slices in the X and Y directions, centered around the tree's center.\n",
    "    \"\"\"\n",
    "    tree_center = point_cloud[point_cloud[:,2].argmax(), :2]\n",
    "    x_slice_mask = (point_cloud[:,0] >= tree_center[0] - slice_thickness/2) & \\\n",
    "                   (point_cloud[:,0] <= tree_center[0] + slice_thickness/2)\n",
    "    y_slice_mask = (point_cloud[:,1] >= tree_center[1] - slice_thickness/2) & \\\n",
    "                   (point_cloud[:,1] <= tree_center[1] + slice_thickness/2)\n",
    "    x_slice = point_cloud[x_slice_mask]\n",
    "    y_slice = point_cloud[y_slice_mask]\n",
    "    return x_slice, y_slice\n",
    "\n",
    "\n",
    "\n",
    "def plot_to_image(figure, dpi):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it as a numpy array, setting the resolution with a high DPI.\n",
    "    \"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    figure.savefig(buf, format='png', bbox_inches='tight', pad_inches=0, dpi=dpi)\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    image = Image.open(buf)\n",
    "    return np.array(image)\n",
    "\n",
    "def plot_section_as_image_with_alpha(slice_data, z_low, z_high, alpha=0.3, output_size=(1000, 1000), dpi=100):\n",
    "    \"\"\"\n",
    "    Create a figure and plot the slice_data with alpha transparency.\n",
    "    Dynamically adjusts plot limits based on the data and resizes the output image to a square format.\n",
    "    \"\"\"\n",
    "    if slice_data.size == 0:\n",
    "        return None  # Return None if there are no data points to plot.\n",
    "\n",
    "    # Determine aspect ratio and figure size\n",
    "    buffer = 0 # Add a buffer around data extents\n",
    "    x_min, x_max = np.min(slice_data[:, 0]) - buffer, np.max(slice_data[:, 0]) + buffer\n",
    "    y_min, y_max = np.min(slice_data[:, 2]) - buffer, np.max(slice_data[:, 2]) + buffer\n",
    "\n",
    "    # Dynamically adjust xlim and ylim to include all points and maintain real tree dimensions\n",
    "    x_range = x_max - x_min\n",
    "    y_range = z_high - z_low  # This should be close to section_height if properly sliced\n",
    "\n",
    "    # Determine the scale factor to use for x and y to maintain aspect ratio\n",
    "    if x_range > y_range:\n",
    "        scale_factor = x_range / y_range\n",
    "        fig_width, fig_height = 10 * scale_factor, 10\n",
    "    else:\n",
    "        scale_factor = y_range / x_range\n",
    "        fig_width, fig_height = 10, 10 * scale_factor\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "    ax.scatter(slice_data[:, 0], slice_data[:, 2], s=3, color='black', alpha=alpha, edgecolors='none')\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_aspect('auto')  # 'auto' allows free aspect ratio that adjusts to specified limits\n",
    "\n",
    "    ax.axis('off')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    return plot_to_image(fig, dpi)\n",
    "    \n",
    "def convert_sections_to_images(point_cloud, section_height, slice_thickness, tree_center, bottom_height, output_dir, base_filename):\n",
    "    max_height =  np.max(point_cloud[:, 2])-bottom_height\n",
    "    num_sections = int(np.ceil(max_height / section_height))\n",
    "\n",
    "    # Normalize point cloud\n",
    "    point_cloud[:, 2]=point_cloud[:, 2]-bottom_height\n",
    "\n",
    "    for i in range(num_sections):\n",
    "        # compute the lower end of the interval\n",
    "        z_low=np.float64(0)\n",
    "        if i>0:\n",
    "            z_low = np.float64(i)*section_height\n",
    "\n",
    "        # get upper end of the interval\n",
    "        z_high = (i +1) * section_height\n",
    "\n",
    "        # slice pointcloud\n",
    "        section_mask = (point_cloud[:, 2] >= z_low) & (point_cloud[:, 2] < z_high)\n",
    "        section_points = point_cloud[section_mask]\n",
    "\n",
    "        # skip if there are no points\n",
    "        if not section_points.size:\n",
    "            continue\n",
    "\n",
    "        # if the tree does not fill the frame then modify the lower and upper limits\n",
    "        if (np.max(section_points[:, 2])-np.min(section_points[:, 2]))<(section_height-0.5):\n",
    "            z_high = np.max(section_points[:, 2])\n",
    "            z_low= z_high-section_height\n",
    "            # slice pointcloud\n",
    "            section_mask = (point_cloud[:, 2] >= z_low) & (point_cloud[:, 2] < z_high)\n",
    "            section_points = point_cloud[section_mask]\n",
    "\n",
    "        \n",
    "        x_section_slice, y_section_slice = slice_tree_center_thick_slices(section_points, slice_thickness)\n",
    "        rotated_section_points = rotate_point_cloud(section_points, 45, tree_center)\n",
    "        x45_section_slice, y45_section_slice = slice_tree_center_thick_slices(rotated_section_points, slice_thickness)\n",
    "\n",
    "        plot_limits = [tree_center[0] - slice_thickness/2, tree_center[0] + slice_thickness/2,\n",
    "                       tree_center[1] - slice_thickness/2, tree_center[1] + slice_thickness/2]\n",
    "\n",
    "        for slice_data, slice_name in zip([x_section_slice, y_section_slice, x45_section_slice, y45_section_slice],\n",
    "                                          ['x', 'y', 'x45', 'y45']):\n",
    "            img_array = plot_section_as_image_with_alpha(slice_data, z_low, z_high, dpi=100)\n",
    "            \n",
    "            # Metadata for filename\n",
    "            min_x_or_y = np.min(slice_data[:, 0 if slice_name in ['x', 'x45'] else 1])\n",
    "            max_x_or_y = np.max(slice_data[:, 0 if slice_name in ['x', 'x45'] else 1])\n",
    "            filename = f\"{output_dir}/{base_filename}_{slice_name}_section_{i}_min{min_x_or_y:.2f}_max{max_x_or_y:.2f}_zmin{z_low:.2f}_zmax{z_high:.2f}.png\"\n",
    "            \n",
    "            Image.fromarray(img_array).save(filename)\n",
    "\n",
    "\n",
    "def process_point_cloud(point_cloud, output_directory, bottom_height, base_filename):\n",
    "    tree_center = point_cloud[point_cloud[:,2].argmax(), :2]\n",
    "    convert_sections_to_images(point_cloud, 10, 10, tree_center,bottom_height, output_directory, base_filename)\n",
    "\n",
    "# Function to get image size\n",
    "def get_image_size(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        return img.size  # (width, height)\n",
    "\n",
    "# Function to convert normalized coordinates to real-world coordinates\n",
    "def convert_to_real_world(px, py, img_width, img_height, x_min, x_max, z_min, z_max):\n",
    "    real_x = px * img_width\n",
    "    real_y = py * img_height\n",
    "    world_x = real_x / img_width * (x_max - x_min) + x_min\n",
    "    world_z = real_y / img_height * (z_max - z_min) + z_min\n",
    "    return world_x, world_z\n",
    "\n",
    "# Function to process a single file\n",
    "def process_file(text_file_path, img_width, img_height, x_min, x_max, z_min, z_max):\n",
    "    real_world_data = []\n",
    "    with open(text_file_path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            parts = line.strip().split()\n",
    "\n",
    "            # get coordinates and confidence for the three keypoints where\n",
    "            # p1: left branch; p2: whorl center; p3: right branch\n",
    "            px1 = float(parts[5])\n",
    "            py1 = float(parts[6])\n",
    "            confidence_p1 = float(parts[7])\n",
    "            px2 = float(parts[8])\n",
    "            py2 = float(parts[9])\n",
    "            confidence_p2 = float(parts[10])\n",
    "            px3 = float(parts[11])\n",
    "            py3 = float(parts[12])\n",
    "            confidence_p3 = float(parts[13])\n",
    "\n",
    "\n",
    "            world_px1, world_pz1 = convert_to_real_world(px1,py1, img_width, img_height, x_min, x_max, z_min, z_max)\n",
    "            world_px2, world_pz2 = convert_to_real_world(px2, py2, img_width, img_height, x_min, x_max, z_min, z_max)\n",
    "            world_px3, world_pz3 = convert_to_real_world(px3, py3, img_width, img_height, x_min, x_max, z_min, z_max)\n",
    "\n",
    "            real_world_data.append((confidence_p1, world_px1, world_pz2, confidence_p2, world_px2, world_pz2,confidence_p3, world_px3, world_pz3))\n",
    "    return real_world_data\n",
    "\n",
    "# Function to calculate the angle at p2 formed by p1 and p3\n",
    "def calculate_angle_at_p2(px1, pz1, px2, pz2, px3, pz3):\n",
    "    # Construct vectors from p2 to p1 and p2 to p3\n",
    "    vector_p2_p1 = np.array([px1 - px2, pz1 - pz2])\n",
    "    vector_p2_p3 = np.array([px3 - px2, pz3 - pz2])\n",
    "    # Calculate the dot product and norms of the vectors\n",
    "    dot_product = np.dot(vector_p2_p1, vector_p2_p3)\n",
    "    norm_p2_p1 = np.linalg.norm(vector_p2_p1)\n",
    "    norm_p2_p3 = np.linalg.norm(vector_p2_p3)\n",
    "    # Calculate the angle in radians and then convert to degrees\n",
    "    angle = np.arccos(np.clip(dot_product / (norm_p2_p1 * norm_p2_p3), -1.0, 1.0))\n",
    "    angle_degrees = np.degrees(angle)\n",
    "    # Check for reflex angle (greater than 180 degrees)\n",
    "    if np.cross(vector_p2_p1, vector_p2_p3) < 0:  # using cross product to determine the orientation\n",
    "        angle_degrees = 360 - angle_degrees\n",
    "    return angle_degrees\n",
    "\n",
    "# Function to calculate Euclidean distance\n",
    "def calculate_distance(px1, pz1, px2, pz2):\n",
    "    return np.sqrt((px1 - px2) ** 2 + (pz1 - pz2) ** 2)\n",
    "\n",
    "# function to process each tree and obtain the detected whorls\n",
    "def pose_detection_tree(treeID, trees,non_tree, dir_root, my_model, dir_pred, min_dist_whorls=0.24):\n",
    "    # skip if treeID ==255\n",
    "    if treeID == 0:\n",
    "        return None  # Skip if treeID is 0\n",
    "\n",
    "    # Folder path containing  the text files\n",
    "    dir_temp_imgs=dir_pred+\"/orig_imgs\"\n",
    "    if not os.path.exists(dir_temp_imgs):\n",
    "       os.makedirs(dir_temp_imgs)\n",
    "    dir_orig_imgs_tree=dir_temp_imgs+\"/\"+str(round(treeID))\n",
    "    if not os.path.exists(dir_orig_imgs_tree):\n",
    "       os.makedirs(dir_orig_imgs_tree)\n",
    "        \n",
    "    dir_pred_out=dir_pred+\"/preds\"\n",
    "    if not os.path.exists(dir_pred_out):\n",
    "       os.makedirs(dir_pred_out)\n",
    "        \n",
    "    dir_labels=dir_pred_out+\"/\"+str(round(treeID))+\"/labels\"\n",
    "\n",
    "    # select the one tree\n",
    "    one_tree_np= trees[trees[:,3]==treeID]\n",
    "    \n",
    "    # compute tree top (will be used later)\n",
    "    top_point= one_tree_np[one_tree_np[:,2]==np.max(one_tree_np[:,2])] \n",
    "    top_height=top_point[0,2]\n",
    "    \n",
    "    # compute tree bottom (will be used later)\n",
    "    bottom_point= one_tree_np[one_tree_np[:,2]==np.min(one_tree_np[:,2])] \n",
    "    bottom_height=bottom_point[0,2]\n",
    "    \n",
    "    if len(non_tree)<0:\n",
    "        # Separate the x, y, and z coordinates\n",
    "        xy_coordinates = non_tree[:, :2]  # Extract x and y\n",
    "        print(xy_coordinates)\n",
    "        print(type(xy_coordinates))\n",
    "        z_values = non_tree[:, 2]  # Extract z\n",
    "    \n",
    "        # Create a KDTree for efficient spatial search\n",
    "        KDtree = cKDTree(xy_coordinates)\n",
    "        \n",
    "        # Given point coordinates (x, y)\n",
    "        x, y = bottom_point[0,0], bottom_point[0,1]\n",
    "        print(type(bottom_point[0,0]))\n",
    "        print([x, y])\n",
    "        print(KDtree)\n",
    "        # Find the nearest point\n",
    "        _, index = KDtree.query([x, y], k=1)\n",
    "        \n",
    "        # Extract the z value of the nearest point\n",
    "        bottom_height = z_values[index]\n",
    "    \n",
    "\n",
    "    ## Create images from point clouds\n",
    "    process_point_cloud(one_tree_np, dir_orig_imgs_tree,bottom_height, 'img_')\n",
    "\n",
    "\n",
    "\n",
    "    ####################################################################################################################################\n",
    "    ## Predict on new data\n",
    "    model=YOLO(my_model)\n",
    "    model.predict(source=dir_orig_imgs_tree,conf=0.3, imgsz=1000, save=True, save_txt=True, project=dir_pred_out, name=str(round(treeID)))  # no arguments needed, dataset and settings remembered\n",
    "\n",
    "\n",
    "    \n",
    "    ####################################################################################################################################\n",
    "    ## Parse output to produce data for the whole tree\n",
    "    \n",
    "    # List all text files in the folder\n",
    "    text_files = [f for f in os.listdir(dir_labels) if f.endswith('.txt')]\n",
    "    print(dir_labels)\n",
    "    # Process each text file\n",
    "    all_data = []\n",
    "    for text_file in text_files:\n",
    "        # Extract the base filename to find the corresponding image file\n",
    "        base_filename = text_file.replace('.txt', '')\n",
    "        image_filename = base_filename + '.png'  # Assuming image extension is .png\n",
    "        image_path = os.path.join(dir_orig_imgs_tree, image_filename)\n",
    "        text_file_path = os.path.join(dir_labels, text_file)\n",
    "        \n",
    "        # Get image size\n",
    "        img_width, img_height = get_image_size(image_path)\n",
    "        \n",
    "        # Extract metadata from the file name\n",
    "        pattern = r\"min(-?\\d+\\.\\d+)_max(-?\\d+\\.\\d+)_zmin(-?\\d+\\.\\d+)_zmax(-?\\d+\\.\\d+)\"\n",
    "    \n",
    "        match = re.search(pattern, text_file)\n",
    "        if match:\n",
    "            x_min, x_max, z_min, z_max = map(float, match.groups())\n",
    "            #x_min, x_max, z_min, z_max = map(float, re.findall(r\"min(-?\\d+\\.\\d+)_max(-?\\d+\\.\\d+)_zmin(-?\\d+\\.\\d+)_zmax(-?\\d+\\.\\d+)\", text_file)[0])\n",
    "            print(x_min)\n",
    "\n",
    "        else:\n",
    "            x_min, x_max, z_min, z_max = map(float, re.findall(r\"min(\\d+\\.\\d+)_max(\\d+\\.\\d+)_zmin(\\d+\\.\\d+)_zmax(\\d+\\.\\d+)\", text_file)[0])\n",
    "        \n",
    "        # Process the file\n",
    "        file_data = process_file(text_file_path, img_width, img_height, x_min, x_max, z_min, z_max)\n",
    "        \n",
    "        # Add filename string to each row and extend the all_data list\n",
    "        slice_direction = base_filename.split('__')[1].split('_section')[0]\n",
    "        all_data.extend([(confidence_p1, world_px1, world_pz2, confidence_p2, world_px2, world_pz2,confidence_p3, world_px3, world_pz3, slice_direction) for confidence_p1, world_px1, world_pz2, confidence_p2, world_px2, world_pz2,confidence_p3, world_px3, world_pz3 in file_data])\n",
    "    \n",
    "    # Create a DataFrame with all data\n",
    "    df_all = pd.DataFrame(all_data, columns=['confidence_p1', 'world_px1', 'world_pz1', 'confidence_p2', 'world_px2', 'world_pz2','confidence_p3', 'world_px3', 'world_pz3','slice_direction'])\n",
    "    df_all['treeID']=treeID\n",
    "    df_all_sorted = df_all.sort_values(by='world_pz2')\n",
    "    \n",
    "    # Applying the functions to the DataFrame\n",
    "    df_all_sorted['branch_opening_angle'] = df_all_sorted.apply(lambda row: calculate_angle_at_p2(row['world_px1'], row['world_pz1'],row['world_px2'], row['world_pz2'],row['world_px3'], row['world_pz3']), axis=1)\n",
    "    #df_all_sorted['branch_opening_angle']=180-df_all_sorted['branch_opening_angle']\n",
    "    df_all_sorted['branch_length_p1_p2'] = df_all_sorted.apply(lambda row: calculate_distance(row['world_px1'], row['world_pz1'], row['world_px3'], row['world_pz3']), axis=1)\n",
    "    df_all_sorted['branch_length_p3_p2'] = df_all_sorted.apply(lambda row: calculate_distance(row['world_px3'], row['world_pz3'], row['world_px2'], row['world_pz2']), axis=1)\n",
    "    #df_all_sorted['branch_length_p3_p1'] = df_all_sorted.apply(lambda row: calculate_distance(row['world_px3'], row['world_pz3'], row['world_px1'], row['world_pz1']), axis=1)\n",
    "\n",
    "    # add tree top and tree bottom points to the sorted dataframe\n",
    "    df_all_sorted.loc[len(df_all_sorted)] = [0, 0,0,1,top_point[0,0], top_height,0,0,0,0,0,0,0,0 ]\n",
    "    #df_all_sorted.loc[len(df_all_sorted)] = [0, 0,0,1,bottom_point[0,0], bottom_height,0,0,0,0,0,0,0,0 ]\n",
    "    \n",
    "    # re-sort the dataframe\n",
    "    df_all_sorted = df_all_sorted.sort_values(by='world_pz2')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####################################################################################################################################\n",
    "    # Cleanup\n",
    "    # subset to select only most confident predictions within each \"min_dist_whorls\" cm interval\n",
    "    # Now, let's iterate through each row and select the one with the largest probability\n",
    "    # if consecutive rows are closer than 0.05 in Z values.\n",
    "    selected_rows = []\n",
    "    current_row = df_all_sorted.iloc[0]\n",
    "    \n",
    "    for index, next_row in df_all_sorted.iterrows():\n",
    "        if (next_row['world_pz2'] - current_row['world_pz2']) < min_dist_whorls:\n",
    "            # If the Z values are closer than 0.05, check the confidence\n",
    "            if next_row['confidence_p2'] > current_row['confidence_p2']:\n",
    "                current_row = next_row\n",
    "        else:\n",
    "            # If they are not closer, add the current row to the selected rows\n",
    "            selected_rows.append(current_row)\n",
    "            current_row = next_row\n",
    "    \n",
    "    # Make sure to add the last row after the loop\n",
    "    selected_rows.append(current_row)\n",
    "    \n",
    "    # Create a DataFrame with the selected rows\n",
    "    df_selected = pd.DataFrame(selected_rows)\n",
    "    \n",
    "    #df_selected\n",
    "    \n",
    "    # Calculating the maximum branch length\n",
    "    df_selected['max_branch_length'] = df_selected[['branch_length_p1_p2', 'branch_length_p3_p2']].max(axis=1)\n",
    "    \n",
    "    # Calculating the average branch length\n",
    "    df_selected['average_branch_length'] = df_selected[['branch_length_p1_p2', 'branch_length_p3_p2']].mean(axis=1)\n",
    "    #df_selected['crown_diam'] = df_selected[['branch_length_p3_p1', 'branch_length_p3_p2']].max(axis=1)\n",
    "\n",
    "    \n",
    "    # Now, replace values greater than 10 with 0 in both columns\n",
    "    df_selected['max_branch_length'] = df_selected['max_branch_length'].apply(lambda x: 0 if x > 10 else x)\n",
    "    df_selected['average_branch_length'] = df_selected['average_branch_length'].apply(lambda x: 0 if x > 10 else x)\n",
    "    #df_selected['crown_diam'] = df_selected['crown_diam'].apply(lambda x: 0 if x > 10 else x)\n",
    "\n",
    "    \n",
    "    ####################################################################################################################################\n",
    "    ## Create pointcloud result\n",
    "    whorls_pc= df_selected[['world_px2','world_pz2','confidence_p2','branch_opening_angle','max_branch_length','average_branch_length']]\n",
    "    whorls_pc['x']=top_point[0,0]\n",
    "    whorls_pc['y']=top_point[0,1]\n",
    "    \n",
    "    # de-normalize z\n",
    "    whorls_pc['z']=whorls_pc['world_pz2']+bottom_height\n",
    "    # add tree ID\n",
    "    #ID = re.findall(r'\\d+', os.path.splitext(os.path.basename(treeID))[0])\n",
    "    ID = int(treeID)\n",
    "    whorls_pc['treeID']=ID    # This should include any processing and return the necessary results\n",
    "\n",
    "    # For demonstration, returning a simple dictionary. This should be replaced with actual processing results\n",
    "    return {'treeID': treeID, 'result': df_selected, 'whorl_pc':whorls_pc}  # Replace with actual result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3523a74-f864-4d55-8db3-09505b0f9a4a",
   "metadata": {},
   "source": [
    "## Define paths and create required directories for temporary or output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca1f6655-3d1b-4550-9121-3671ef69a71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\demo_data.laz']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directory to where point cloud (*.las or *.laz) forest scenes are stored (they need to have treeIDs for each point!)\n",
    "dir_root=\"data\"\n",
    "\n",
    "# directory to where YOLO predictions are stored\n",
    "dir_output = os.path.join(dir_root, \"results\")  # path to where to store the final results\n",
    "dir_pred = os.path.join(dir_root, \"pred_temp\")  # temp path to where to store the intermediate prediction\n",
    "dir_temp_imgs = os.path.join(dir_pred, \"orig_imgs\") # Further subdirectories within 'dir_pred'\n",
    "\n",
    "# Ensure directories exist without throwing an error if they already do\n",
    "os.makedirs(dir_pred, exist_ok=True)\n",
    "os.makedirs(dir_output, exist_ok=True)\n",
    "os.makedirs(dir_temp_imgs, exist_ok=True)\n",
    "\n",
    "# Find all .las and .laz files in the root folder\n",
    "las_files = glob.glob(os.path.join(dir_root, '*.las'))\n",
    "laz_files = glob.glob(os.path.join(dir_root, '*.laz'))\n",
    "\n",
    "# Combine the lists of files\n",
    "all_files = las_files + laz_files\n",
    "all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf9b8ba-8298-4d9a-ac90-6581fc8b5029",
   "metadata": {},
   "source": [
    "## Define parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af483675-eccd-4b80-8cfc-8a891d74572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum distance between whorls (used to remove duplicates)\n",
    "min_internodal_d=0.01 # in m\n",
    "\n",
    "# pose model\n",
    "my_model=\"whorl_pose_nano_1000px/weights/best.pt\"\n",
    "\n",
    "# label for the column with tree instance unique identifiers\n",
    "tree_id_label='treeID' \n",
    "\n",
    "# label for the column with semantic labels (non required)\n",
    "semantic_label='semantic' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7801c0b-96f1-4a46-a447-88976c3ab0dd",
   "metadata": {},
   "source": [
    "## Run for each file in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc138dc-42c6-44ac-85cb-a4d22d1d66bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data\\demo_data.laz\n"
     ]
    }
   ],
   "source": [
    "for filename in all_files:\n",
    "    print(\"Processing: \"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafafe31-63fb-447f-a9bd-c6098aa44f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# shutil.rmtree(dir_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b389746d-3224-48fb-a7ce-8c7060ffa865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree points: 100%\n",
      "Non-tree points: 0%\n"
     ]
    }
   ],
   "source": [
    "# Read in the forest segmented data\n",
    "las = laspy.read(filename)\n",
    "\n",
    "# convert to a numpy array \n",
    "las_np = np.vstack((las.x, las.y, las.z,  getattr(las, tree_id_label),  getattr(las, semantic_label))).transpose()\n",
    "\n",
    "# split tree/non-tree (this assumes that the label \n",
    "trees= las_np[las_np[:,4]!=0]\n",
    "non_tree= las_np[las_np[:,4]==0]\n",
    "\n",
    "print(\"tree points: \"+ str(round(len(trees)/len(las_np)*100))+\"%\")\n",
    "print(\"Non-tree points: \"+ str(round(len(non_tree)/len(las_np)*100))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "764c8a76-c808-449f-b7fe-5bd4c36ebf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_preds=dir_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10a0659-1de1-4316-8fd9-fbf3570dace7",
   "metadata": {},
   "source": [
    "# Whorl detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47a602ee-1101-4737-85bc-e831ea518308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[1000] must be multiple of max stride 32, updating to [1024]\n",
      "\n",
      "WARNING  imgsz=[1000] must be multiple of max stride 32, updating to [1024]\n",
      "image 1/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409022\\img__x45_section_0_min4.53_max9.16_zmin0.00_zmax10.00.png: 1024x480 11 whorlss, 55.0ms\n",
      "image 1/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409020\\img__x45_section_0_min-1.93_max1.90_zmin0.00_zmax10.00.png: 1024x416 15 whorlss, 63.0ms\n",
      "image 2/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409022\\img__x45_section_1_min4.53_max9.16_zmin2.50_zmax12.50.png: 1024x480 18 whorlss, 6.0ms\n",
      "image 2/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409020\\img__x45_section_1_min-1.93_max1.90_zmin1.39_zmax11.39.png: 1024x416 17 whorlss, 24.0ms\n",
      "image 3/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409022\\img__x_section_0_min4.74_max8.38_zmin0.00_zmax10.00.png: 1024x384 10 whorlss, 57.0ms\n",
      "image 3/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409020\\img__x_section_0_min-2.13_max2.38_zmin0.00_zmax10.00.png: 1024x480 14 whorlss, 59.0ms\n",
      "image 4/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409022\\img__x_section_1_min4.74_max8.38_zmin2.50_zmax12.50.png: 1024x384 12 whorlss, 9.0ms\n",
      "image 4/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409020\\img__x_section_1_min-1.92_max2.38_zmin1.39_zmax11.39.png: 1024x448 13 whorlss, 52.0ms\n",
      "image 5/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409022\\img__y45_section_0_min-2.37_max2.78_zmin0.00_zmax10.00.png: 1024x480 11 whorlss, 18.0ms\n",
      "image 5/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409020\\img__y45_section_0_min1.67_max5.99_zmin0.00_zmax10.00.png: 1024x416 15 whorlss, 11.0ms\n",
      "image 6/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409022\\img__y45_section_1_min-2.36_max2.62_zmin2.50_zmax12.50.png: 1024x480 18 whorlss, 14.0ms\n",
      "image 6/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409020\\img__y45_section_1_min1.67_max5.99_zmin1.39_zmax11.39.png: 1024x416 17 whorlss, 22.0ms\n",
      "image 7/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409022\\img__y_section_0_min-1.45_max3.19_zmin0.00_zmax10.00.png: 1024x384 10 whorlss, 23.0ms\n",
      "image 8/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409022\\img__y_section_1_min-1.45_max3.17_zmin2.50_zmax12.50.png: 1024x384 12 whorlss, 15.0ms\n",
      "image 7/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409020\\img__y_section_0_min1.39_max6.14_zmin0.00_zmax10.00.png: 1024x480 14 whorlss, 12.0ms\n",
      "Speed: 5.1ms preprocess, 24.6ms inference, 204.5ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "Results saved to \u001b[1mdata\\pred_temp\\preds\\25409022\u001b[0m\n",
      "8 labels saved to data\\pred_temp\\preds\\25409022\\labels\n",
      "data\\pred_temp/preds/25409022/labels\n",
      "4.53\n",
      "4.53\n",
      "4.74\n",
      "4.74\n",
      "-2.37\n",
      "-2.36\n",
      "-1.45\n",
      "-1.45\n",
      "image 8/8 C:\\Users\\stpu\\whorl_pose_detector\\data\\pred_temp\\orig_imgs\\25409020\\img__y_section_1_min1.39_max5.78_zmin1.39_zmax11.39.png: 1024x448 13 whorlss, 9.0ms\n",
      "Speed: 5.1ms preprocess, 31.5ms inference, 203.8ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "Results saved to \u001b[1mdata\\pred_temp\\preds\\25409020\u001b[0m\n",
      "8 labels saved to data\\pred_temp\\preds\\25409020\\labels\n",
      "data\\pred_temp/preds/25409020/labels\n",
      "-1.93\n",
      "-1.93\n",
      "-2.13\n",
      "-1.92\n",
      "1.67\n",
      "1.67\n",
      "1.39\n",
      "1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stpu\\AppData\\Local\\Temp\\ipykernel_30404\\2359855698.py:361: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  whorls_pc['x']=top_point[0,0]\n",
      "C:\\Users\\stpu\\AppData\\Local\\Temp\\ipykernel_30404\\2359855698.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  whorls_pc['y']=top_point[0,1]\n",
      "C:\\Users\\stpu\\AppData\\Local\\Temp\\ipykernel_30404\\2359855698.py:365: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  whorls_pc['z']=whorls_pc['world_pz2']+bottom_height\n",
      "C:\\Users\\stpu\\AppData\\Local\\Temp\\ipykernel_30404\\2359855698.py:369: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  whorls_pc['treeID']=ID    # This should include any processing and return the necessary results\n",
      "C:\\Users\\stpu\\AppData\\Local\\Temp\\ipykernel_30404\\2359855698.py:361: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  whorls_pc['x']=top_point[0,0]\n",
      "C:\\Users\\stpu\\AppData\\Local\\Temp\\ipykernel_30404\\2359855698.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  whorls_pc['y']=top_point[0,1]\n",
      "C:\\Users\\stpu\\AppData\\Local\\Temp\\ipykernel_30404\\2359855698.py:365: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  whorls_pc['z']=whorls_pc['world_pz2']+bottom_height\n",
      "C:\\Users\\stpu\\AppData\\Local\\Temp\\ipykernel_30404\\2359855698.py:369: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  whorls_pc['treeID']=ID    # This should include any processing and return the necessary results\n"
     ]
    }
   ],
   "source": [
    "# Parallel individual tree whorl pose detection\n",
    "unique_treeIDs = np.unique(getattr(las, tree_id_label))\n",
    "results = []\n",
    "\n",
    "#os.makedirs(\"test_whorls_maria/forest/pred_temp/preds\", exist_ok=True)\n",
    "\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    # Submitting tasks to the executor\n",
    "    future_to_treeID = {\n",
    "        executor.submit(\n",
    "            pose_detection_tree, \n",
    "            treeID=treeID,         # Pass treeID as a keyword argument\n",
    "            trees=trees, \n",
    "            non_tree=non_tree, \n",
    "            dir_root=dir_root, \n",
    "            my_model=my_model, \n",
    "            dir_pred=dir_pred, \n",
    "            min_dist_whorls=min_internodal_d  # Pass min_dist_whorls as a keyword argument\n",
    "        ): treeID \n",
    "        for treeID in unique_treeIDs\n",
    "    }\n",
    "    \n",
    "    # Collecting results as they complete\n",
    "    for future in concurrent.futures.as_completed(future_to_treeID):\n",
    "        treeID = future_to_treeID[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "            if data is not None:\n",
    "                results.append(data)\n",
    "        except Exception as exc:\n",
    "            print(f'TreeID {treeID} generated an exception: {exc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4b3fbd-873a-4683-9de5-baaf8ac65ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "#shutil.rmtree(\"C:/Users/stpu/whorl_pose_detector/test_whorls_maria/forest/pred_temp/orig_imgs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65583e4a-f370-4111-a582-cdc2b26d986e",
   "metadata": {},
   "source": [
    "## Post-processing of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4d71255-8566-4c6c-b467-39f8bd99a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing the results\n",
    "# Creating a dictionary mapping treeID to its result\n",
    "results_dict = {result['treeID']: result['result'] for result in results if result is not None}\n",
    "\n",
    "# Merging the 'whorl_pc' DataFrames from each result\n",
    "whorls_pc_dfs = [result['whorl_pc'] for result in results if result is not None and 'whorl_pc' in result]\n",
    "whorld_df = pd.concat(whorls_pc_dfs, ignore_index=True)\n",
    "\n",
    "# correct z\n",
    "whorld_df.loc[whorld_df['branch_opening_angle'] == 0, 'z'] = whorld_df['world_pz2']\n",
    "\n",
    "# remove negative whorls\n",
    "whorld_df= whorld_df[whorld_df['world_pz2']>=0]\n",
    "\n",
    "\n",
    "# write out the output\n",
    "whorld_df.to_csv(dir_output+'/'+os.path.splitext(os.path.basename(filename))[0]+'_'+str(round(min_internodal_d*100))+'cmThresh_whorls_pc_HKL2model.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88638710-2ecd-45da-87c4-b00848fa2d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     world_px2  world_pz2  confidence_p2  branch_opening_angle  \\\n",
      "0     7.145728   0.273531       0.960763              5.969818   \n",
      "1     1.752101   0.499852       0.977073              8.872340   \n",
      "2     0.562580   0.766537       0.999808            159.023735   \n",
      "3     7.209631   1.263350       0.999027            150.733587   \n",
      "4     7.273557   1.464500       0.997177            151.758838   \n",
      "..         ...        ...            ...                   ...   \n",
      "101   0.275257  10.209120       0.997685            176.362206   \n",
      "102   3.970931  10.256400       0.996999            191.226363   \n",
      "103   3.637505  10.802320       0.987156            191.187685   \n",
      "104   3.594131  10.896220       0.838436            173.924614   \n",
      "105   0.324000  10.962000       1.000000              0.000000   \n",
      "\n",
      "     max_branch_length  average_branch_length      x      y          z  \\\n",
      "0             2.629991               1.451761  7.219  0.675  -1.007469   \n",
      "1             3.240880               2.716941  7.219  0.675  -0.781148   \n",
      "2             1.713142               1.291053  7.219  0.675  -0.514463   \n",
      "3             2.329140               1.752136  7.219  0.675  -0.017650   \n",
      "4             2.873173               2.159196  7.219  0.675   0.183500   \n",
      "..                 ...                    ...    ...    ...        ...   \n",
      "101           3.948233               2.966569  0.324  3.588   9.781120   \n",
      "102           4.010259               2.961209  0.324  3.588   9.828400   \n",
      "103           3.823385               2.880956  0.324  3.588  10.374320   \n",
      "104           3.783275               2.683800  0.324  3.588  10.468220   \n",
      "105           0.000000               0.000000  0.324  3.588  10.962000   \n",
      "\n",
      "       treeID  \n",
      "0    25409022  \n",
      "1    25409022  \n",
      "2    25409022  \n",
      "3    25409022  \n",
      "4    25409022  \n",
      "..        ...  \n",
      "101  25409020  \n",
      "102  25409020  \n",
      "103  25409020  \n",
      "104  25409020  \n",
      "105  25409020  \n",
      "\n",
      "[106 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(whorld_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970f1200-52a2-4456-987c-0e424af38146",
   "metadata": {},
   "source": [
    "# PLOTTING (to edit!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "320a030e-5cac-46ff-9aba-82ce097b3d45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_selected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m cm \u001b[38;5;241m=\u001b[39m LinearSegmentedColormap\u001b[38;5;241m.\u001b[39mfrom_list(cmap_name, colors, N\u001b[38;5;241m=\u001b[39mn_bins)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Normalizing the branch_opening_angle to fit the range [0, 1] for our colormap\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Since yellow corresponds to 180 degrees in our scale, we adjust the normalization accordingly\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#norm = plt.Normalize(0, 2*180)\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df_selected_no_topBottom\u001b[38;5;241m=\u001b[39m\u001b[43mdf_selected\u001b[49m[df_selected[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence_p1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Plotting all of the World_Z values\u001b[39;00m\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m)) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_selected' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Define a custom colormap using blue, yellow, and red, where yellow corresponds to the midpoint (180 degrees)\n",
    "colors = [(0, 0, 1), (1, 1, 0), (1, 0, 0)]  # Blue -> Yellow -> Red\n",
    "n_bins = 100  # Discretizes the interpolation into bins\n",
    "cmap_name = 'custom_colormap'\n",
    "cm = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)\n",
    "\n",
    "# Normalizing the branch_opening_angle to fit the range [0, 1] for our colormap\n",
    "# Since yellow corresponds to 180 degrees in our scale, we adjust the normalization accordingly\n",
    "#norm = plt.Normalize(0, 2*180)\n",
    "\n",
    "df_selected_no_topBottom=df_selected[df_selected['confidence_p1']>0]\n",
    "# Plotting all of the World_Z values\n",
    "plt.figure(figsize=(10, 6)) \n",
    "# whorld_df\n",
    "scatter = plt.scatter(range(len(df_selected)), df_selected['world_pz2'], c=df_selected['branch_opening_angle'], cmap='viridis',alpha=0.8)\n",
    "#scatter = plt.scatter(range(len(df_selected)), df_selected['world_pz2'], df_selected['branch_opening_angle'], cmap=cm,alpha=0.8)\n",
    "plt.colorbar(scatter, label='Branch Opening Angle (Degrees)')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('world_pz2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dadb6a0b-427c-485f-af08-7d71a6c4d43d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_selected_no_topBottom' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mmax(\u001b[43mdf_selected_no_topBottom\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbranch_opening_angle\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_selected_no_topBottom' is not defined"
     ]
    }
   ],
   "source": [
    "np.max(df_selected_no_topBottom['branch_opening_angle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca333f8b-b3d0-48f6-9d0d-c0a2b6231ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a custom colormap using blue, yellow, and red, where yellow corresponds to 180 degrees\n",
    "colors = [(0, 0, 1), (1, 1, 0), (1, 0, 0)]  # Blue -> Yellow -> Red\n",
    "cmap_name = 'custom_colormap'\n",
    "cm = LinearSegmentedColormap.from_list(cmap_name, colors, N=20)\n",
    "\n",
    "# Normalizing the branch_opening_angle to fit the fixed range [0, 360] for our colormap\n",
    "norm = plt.Normalize(np.min(df_all_sorted['branch_opening_angle']), np.max(df_all_sorted['branch_opening_angle']))\n",
    "\n",
    "df_selected_no_topBottom=df_selected[df_selected['confidence_p1']>0]\n",
    "# Plotting with the fixed color scale\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(range(len(df_all_sorted)), df_all_sorted['world_pz2'], c=df_all_sorted['branch_opening_angle'], cmap=cm, norm=norm)\n",
    "plt.colorbar(scatter, label='Branch Opening Angle (Degrees)')\n",
    "plt.xlabel('Row Number')\n",
    "plt.ylabel('world_pz2')\n",
    "plt.title('Plot of world_pz2 Colored by Branch Opening Angle Using Fixed Color Range')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332fd68-c51f-4811-8a0c-d87fe5cbd7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two different colormaps for values below and above 180 degrees\n",
    "cmap_below_180 = LinearSegmentedColormap.from_list('below_180', [(1, 1, 1), (0, 0, 1)], N=100)  # White to blue\n",
    "cmap_above_180 = LinearSegmentedColormap.from_list('above_180', [(1, 1, 1), (1, 0, 0)], N=100)  # White to red\n",
    "\n",
    "# Function to apply the appropriate colormap based on the value\n",
    "def apply_cmap(value):\n",
    "    if value <= 180:\n",
    "        return cmap_below_180(norm(value))\n",
    "    else:\n",
    "        return cmap_above_180(norm(value - 180))\n",
    "\n",
    "# Apply the color mapping to each value\n",
    "colors = df_selected['branch_opening_angle'].apply(apply_cmap)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(range(len(df_selected)), df_selected['world_pz2'], c=colors)\n",
    "plt.colorbar(scatter, label='Branch Opening Angle (Degrees)')\n",
    "\n",
    "# Create custom colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=LinearSegmentedColormap.from_list('custom', [(0, 0, 1), (1, 0, 0)]), norm=norm)\n",
    "sm.set_array([])  # You have to set_array for the ScalarMappable.\n",
    "#cbar = plt.colorbar(sm, ticks=[0, 180, 360])\n",
    "#cbar.ax.set_yticklabels(['0°', '180°', '360°'])  # Set the tick labels\n",
    "\n",
    "#plt.xticks(row_numbers)\n",
    "plt.xlabel('Row Number')\n",
    "plt.ylabel('world_pz2')\n",
    "plt.title('Plot of world_pz2 Colored by Branch Opening Angle with Custom Color Bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e16963-5525-4aad-98f2-7445e77bc1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Adjusting the colormap to span the full range from 0 to 1\n",
    "min_angle = df_selected[\"branch_opening_angle\"].min()\n",
    "max_angle = df_selected[\"branch_opening_angle\"].max()\n",
    "\n",
    "# Define color ranges in terms of the angle range\n",
    "color_map_data = [\n",
    "    (0, 'darkblue'), \n",
    "    ((180 - min_angle) / (max_angle - min_angle), 'lightblue'),\n",
    "    ((180.9 - min_angle) / (max_angle - min_angle), 'white'),\n",
    "    ((250 - min_angle) / (max_angle - min_angle), 'lightpink'),\n",
    "    (1, 'darkred')\n",
    "]\n",
    "\n",
    "# Create the colormap\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list('custom', color_map_data)\n",
    "\n",
    "# Normalize the color map to the range of branch_opening_angle\n",
    "norm = mcolors.Normalize(vmin=min_angle, vmax=max_angle)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(range(len(df_selected)), df_selected[\"world_pz2\"], c=df_selected[\"branch_opening_angle\"], cmap=cmap, norm=norm)\n",
    "#plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap))\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('world_pz2')\n",
    "plt.title('world_pz2 vs Index Colored by Branch Opening Angle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480276c-1ce6-49d5-b996-f66cfc059673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa84ac-5947-42b3-8b2a-f8a45ab58ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
